# 模型路由配置

## 快捷指令约定

| 用户指令 | 切换到的模型 |
|---------|-------------|
| `use glm` | zai/glm-4.7 |
| `use kimi` | kimi-coding/k2p5 |

---

## 自动模型选择规则

### 何时使用 Kimi

✅ **推荐场景**：
- 代码阅读/理解（长上下文支持，中文理解优势）
- 架构设计（需要深度理解和推理）
- 复杂问题诊断（需要多轮推理和上下文）
- 代码审查（需要深度理解代码意图）
- 需要理解大型代码库（文件数>10，代码量>1000行）
- 中文技术文档处理（中文比例>50%）
- 复杂架构分析（涉及多个模块/系统）
- 长对话上下文（对话轮次>5轮）
- 代码安全审查或性能优化分析

❌ **不推荐场景**：
- 简单的代码生成任务（成本较高）
- 重复性高的批量操作（调用消耗快）
- 对成本敏感的高频使用场景

---

### 何时使用 GLM

✅ **推荐场景**：
- 简单 Bug 修复（快速响应，性价比高）
- 单元测试编写（模式化任务，小模型足够）
- 代码生成/重构（GLM快速生成，Kimi质量把关）
- 代码片段生成（<100行）
- 代码格式化和规范化
- 需要多轮迭代的编程任务（会话计费优势）

❌ **不推荐场景**：
- 对服务质量稳定性要求极高的关键业务
- 需要深度推理的复杂架构设计

---

## 自动路由策略

### 用户未指定模型时的决策流程

1. **检查任务类型**：
   - 阅读/理解代码 → Kimi
   - 简单生成/修复 → GLM
   - 架构/诊断 → Kimi
   - 单元测试/格式化 → GLM

2. **检查任务复杂度**：
   - 代码量>1000行或文件数>10 → Kimi
   - 对话轮次>5轮 → Kimi
   - 需要多轮推理 → Kimi
   - 简单任务 → GLM

3. **检查语言偏好**：
   - 中文比例>50% → Kimi
   - 英文为主 → GLM

4. **决策后通知**：
   - 在回复开头标注："🤖 使用 Kimi" 或 "🤖 使用 GLM"

---

## 模型切换流程

### 手动切换

1. 用户发送 `use glm` 或 `use kimi`
2. 识别指令 → 调用 `session_status(model="...")`
3. 回复确认："已切换到 [模型]"
4. 后续消息使用新模型

### 自动切换

1. 分析用户任务类型
2. 根据规则选择模型
3. 标注使用的模型
4. 如果与当前模型不同，可选择是否切换

---

## 版本历史

- **2026-02-12**: 初始版本
  - 定义快捷指令约定
  - 定义场景选择规则
  - 定义自动路由策略
